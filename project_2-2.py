# -*- coding: utf-8 -*-
"""Project #2-2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18lViyv6EJIuqsxjPHFK4thU9T5KCEL5s
"""

from google.colab import files
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# CSV 파일 업로드
uploaded = files.upload()

# 데이터프레임 생성 및 결측값 대체
data_df = pd.read_csv('2019_kbo_for_kaggle_v2.csv')
data_df = data_df.fillna(data_df.mean())

# 데이터프레임을 'year' 기준으로 오름차순 정렬
def sort_dataset(dataset_df):
    sorted_df = dataset_df.sort_values(by='year')
    return sorted_df

# 데이터프레임을 train과 test로 나누어 반환 (label은 0.001을 곱해 rescale)
def split_dataset(dataset_df):
    train_df, test_df = train_test_split(dataset_df, test_size=0.2, random_state=42)

    X_train = train_df.drop(columns=['salary'])  # Feature
    Y_train = train_df['salary'] * 0.001  # Label (rescaled)

    X_test = test_df.drop(columns=['salary'])  # Feature
    Y_test = test_df['salary'] * 0.001  # Label (rescaled)

    return X_train, X_test, Y_train, Y_test

# 숫자형 열만 추출하여 반환
def extract_numerical_cols(dataset_df):
    numerical_cols = dataset_df[['age', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR',
                                 'RBI', 'SB', 'CS', 'BB', 'HBP', 'SO', 'GDP', 'fly', 'war']]
    return numerical_cols

# 의사결정 트리 모델 학습 및 예측
def train_predict_decision_tree(X_train, Y_train, X_test):
    dt_model = DecisionTreeRegressor(random_state=42)
    dt_model.fit(X_train, Y_train)
    dt_predictions = dt_model.predict(X_test)
    return dt_predictions

# 랜덤 포레스트 모델 학습 및 예측
def train_predict_random_forest(X_train, Y_train, X_test):
    rf_model = RandomForestRegressor(random_state=42)
    rf_model.fit(X_train, Y_train)
    rf_predictions = rf_model.predict(X_test)
    return rf_predictions

# SVM 모델 학습 및 예측
def train_predict_svm(X_train, Y_train, X_test):
    scaler = StandardScaler()
    svm_model = SVR()
    svm_model_pipeline = Pipeline([('scaler', scaler), ('svm', svm_model)])

    svm_model_pipeline.fit(X_train, Y_train)
    svm_predictions = svm_model_pipeline.predict(X_test)
    return svm_predictions

# RMSE 계산
def calculate_RMSE(labels, predictions):
    rmse = mean_squared_error(labels, predictions, squared=False)
    return rmse

def main():
    # 데이터 정렬 및 train, test 데이터 분리
    sorted_df = sort_dataset(data_df)
    X_train, X_test, Y_train, Y_test = split_dataset(sorted_df)

    # Feature에서 숫자형 열만 추출
    X_train = extract_numerical_cols(X_train)
    X_test = extract_numerical_cols(X_test)

    # 의사결정 트리, 랜덤 포레스트, SVM 모델 학습 및 예측
    dt_predictions = train_predict_decision_tree(X_train, Y_train, X_test)
    rf_predictions = train_predict_random_forest(X_train, Y_train, X_test)
    svm_predictions = train_predict_svm(X_train, Y_train, X_test)

    # RMSE 계산 및 출력
    print("Decision Tree Test RMSE: ", calculate_RMSE(Y_test, dt_predictions))
    print("Random Forest Test RMSE: ", calculate_RMSE(Y_test, rf_predictions))
    print("SVM Test RMSE: ", calculate_RMSE(Y_test, svm_predictions))

if __name__ == '__main__':
    main()
